{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_extlist(path_dataset, extension='.txt'):\n",
    "    file_list = []\n",
    "    for (path, dir, files) in os.walk(path_dataset):\n",
    "        for filename in files:\n",
    "            ext = os.path.splitext(filename)[-1]\n",
    "            if ext == extension:\n",
    "                file_list.append(path + \"/\" + filename)\n",
    "\n",
    "    return file_list\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "from scipy import io\n",
    "def mat2txt(mat_path, scene_path):\n",
    "    mat_file = io.loadmat(mat_path)\n",
    "    file_name = mat_path.split('/')[-1]\n",
    "    file_name = os.path.splitext(file_name)[0] + '.txt'\n",
    "    f = open(scene_path + '/' + file_name, 'w')\n",
    "    for point in mat_file['image_info'][0][0][0][0][0]:\n",
    "        contents = str(point[0]) + ' ' + str(point[1]) + '\\n'\n",
    "        f.writelines(contents)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/usr/src/app/CrowdCounting-P2PNet/shanghaitechB/train_data'\n",
    "test_path = '/usr/src/app/CrowdCounting-P2PNet/shanghaitechB/test_data'\n",
    "\n",
    "train_copy_path = '/usr/src/app/CrowdCounting-P2PNet/datasets/ver1/train'\n",
    "test_copy_path = '/usr/src/app/CrowdCounting-P2PNet/datasets/ver1/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = find_extlist(train_path, '.jpg')\n",
    "test_img_list = find_extlist(test_path, '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "for train_img in train_img_list:\n",
    "    train_sp = train_img.split('/')\n",
    "    train_sp[-2] = 'ground-truth'\n",
    "    train_sp[-1] =  'GT_' + os.path.splitext(train_sp[-1])[0] + '.mat'\n",
    "    train_mat = '/'.join(train_sp)\n",
    "    print(train_mat)\n",
    "    scene = os.path.splitext(train_sp[-1].split('_')[-1])[0]\n",
    "    scene = train_copy_path + '/scene' + scene\n",
    "    createFolder(scene)\n",
    "    shutil.copy2(train_img, scene)\n",
    "    mat2txt(train_mat, scene)\n",
    "\n",
    "for test_img in test_img_list:\n",
    "    test_sp = test_img.split('/')\n",
    "    test_sp[-2] = 'ground-truth'\n",
    "    test_sp[-1] =  'GT_' + os.path.splitext(test_sp[-1])[0] + '.mat'\n",
    "    test_mat = '/'.join(test_sp)\n",
    "    print(test_mat)\n",
    "    scene = os.path.splitext(test_sp[-1].split('_')[-1])[0]\n",
    "    scene = test_copy_path + '/scene' + scene\n",
    "    createFolder(scene)\n",
    "    shutil.copy2(test_img, scene)\n",
    "    mat2txt(test_mat, scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeversion(ver1_path, ver2_path, root_path='./datasets'):\n",
    "    ver1_list = find_extlist(ver1_path, '.jpg')\n",
    "    ver2_list = find_extlist(ver2_path, '.jpg')\n",
    "    cnt = 1\n",
    "    while True:\n",
    "        if os.path.isdir('/'.join([root_path,'ver{}'.format(cnt)])):\n",
    "            cnt += 1\n",
    "            continue\n",
    "        else:\n",
    "            os.mkdir('/'.join([root_path,'ver{}'.format(cnt)]))\n",
    "            os.mkdir('/'.join([root_path,'ver{}'.format(cnt), 'train']))\n",
    "            os.mkdir('/'.join([root_path,'ver{}'.format(cnt), 'test']))\n",
    "            save_path = '/'.join([root_path,'ver{}'.format(cnt)])\n",
    "            break\n",
    "    \n",
    "    train_cnt = 1\n",
    "    test_cnt = 1\n",
    "\n",
    "    for file in ver1_list:\n",
    "        if 'train' in file:\n",
    "            cnt = train_cnt\n",
    "            train_cnt += 1\n",
    "            folder_name = '/scene' + str(cnt)\n",
    "            folder_path = save_path + '/train' + folder_name\n",
    "        else:\n",
    "            cnt = test_cnt\n",
    "            test_cnt += 1\n",
    "            folder_name = '/scene' + str(cnt)\n",
    "            folder_path = save_path + '/test' + folder_name\n",
    "        \n",
    "        img_file = '/IMG_' + str(cnt) + '.jpg'\n",
    "        ann_file = '/GT_IMG_' + str(cnt) + '.txt'\n",
    "\n",
    "        if os.path.isdir(folder_path) == False:\n",
    "            os.mkdir(folder_path)\n",
    "        \n",
    "        ann_path = file.split('/')\n",
    "        ann_path[-1] = 'GT_IMG_' + os.path.splitext(ann_path[-1])[0].split('_')[-1] + '.txt'\n",
    "        ann_path = '/'.join(ann_path)\n",
    "\n",
    "        shutil.copy2(file, folder_path + img_file)\n",
    "        shutil.copy2(ann_path, folder_path + ann_file)\n",
    "\n",
    "    for file in ver2_list:\n",
    "        if 'train' in file:\n",
    "            cnt = train_cnt\n",
    "            train_cnt += 1\n",
    "            folder_name = '/scene' + str(cnt)\n",
    "            folder_path = save_path + '/train' + folder_name\n",
    "        else:\n",
    "            cnt = test_cnt\n",
    "            test_cnt += 1\n",
    "            folder_name = '/scene' + str(cnt)\n",
    "            folder_path = save_path + '/test' + folder_name\n",
    "        \n",
    "        img_file = '/IMG_' + str(cnt) + '.jpg'\n",
    "        ann_file = '/GT_IMG_' + str(cnt) + '.txt'\n",
    "\n",
    "        if os.path.isdir(folder_path) == False:\n",
    "            os.mkdir(folder_path)\n",
    "\n",
    "        ann_path = file.split('/')\n",
    "        ann_path[-1] = 'GT_IMG_' + os.path.splitext(ann_path[-1])[0].split('_')[-1] + '.txt'\n",
    "        ann_path = '/'.join(ann_path)\n",
    "\n",
    "        shutil.copy2(file, folder_path + img_file)\n",
    "        shutil.copy2(ann_path, folder_path + ann_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeversion('/usr/src/app/CrowdCounting-P2PNet/datasets/ver1', '/usr/src/app/CrowdCounting-P2PNet/datasets/ver2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = 'scene1'\n",
    "a.split('scene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_list = find_extlist('/usr/src/app/CrowdCounting-P2PNet/datasets/ver3/train', '.jpg')\n",
    "file = open('/usr/src/app/CrowdCounting-P2PNet/datasets/ver3/train.list', 'w')\n",
    "for img_path in img_path_list:\n",
    "    img_path = img_path.split('datasets/ver3/')[-1]\n",
    "    mat_path = os.path.splitext(img_path)[0] + '.txt'\n",
    "    contents = img_path + ' ' + mat_path + '\\n'\n",
    "    file.writelines(contents)\n",
    "\n",
    "file.close()\n",
    "\n",
    "img_path_list = find_extlist('/usr/src/app/CrowdCounting-P2PNet/datasets/ver3/train', '.jpg')\n",
    "file = open('/usr/src/app/CrowdCounting-P2PNet/datasets/ver3/test.list', 'w')\n",
    "for img_path in img_path_list:\n",
    "    img_path = img_path.split('datasets/ver3/')[-1]\n",
    "    mat_path = os.path.splitext(img_path)[0] + '.txt'\n",
    "    contents = img_path + ' ' + mat_path + '\\n'\n",
    "    file.writelines(contents)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as standard_transforms\n",
    "from collections import namedtuple, OrderedDict\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{}'.format('0')\n",
    "device = torch.device('cuda')\n",
    "Binding = namedtuple('Binding', ('name', 'dtype', 'shape', 'data', 'ptr'))\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "with open('p2pnet_tensorrt.engine', 'rb') as f, trt.Runtime(logger) as runtime:\n",
    "    model = runtime.deserialize_cuda_engine(f.read())\n",
    "context = model.create_execution_context()\n",
    "bindings = OrderedDict()\n",
    "#fp16 = False  # default updated below\n",
    "dynamic = False\n",
    "for index in range(model.num_bindings):\n",
    "    name = model.get_binding_name(index)\n",
    "    dtype = trt.nptype(model.get_binding_dtype(index))\n",
    "    if model.binding_is_input(index):\n",
    "        if -1 in tuple(model.get_binding_shape(index)):  # dynamic\n",
    "            dynamic = True\n",
    "            context.set_binding_shape(index, tuple(model.get_profile_shape(0, index)[2]))\n",
    "        if dtype == np.float16:\n",
    "            fp16 = True\n",
    "    shape = tuple(context.get_binding_shape(index))\n",
    "    im = torch.from_numpy(np.empty(shape, dtype=dtype)).to(device)\n",
    "    bindings[name] = Binding(name, dtype, shape, im, int(im.data_ptr()))\n",
    "binding_addrs = OrderedDict((n, d.ptr) for n, d in bindings.items())\n",
    "batch_size = bindings['images'].shape[0]  # if dynamic, this is instead max batch size\n",
    "\n",
    "img_path = \"./vis/demo1.jpg\"\n",
    "# load the images\n",
    "img_raw = Image.open(img_path).convert('RGB')\n",
    "# round the size\n",
    "width, height = img_raw.size\n",
    "new_width = width // 128 * 128\n",
    "new_height = height // 128 * 128\n",
    "img_raw = img_raw.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(), \n",
    "        standard_transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "samples = transform(img_raw)\n",
    "samples = torch.Tensor(samples).unsqueeze(0)\n",
    "samples = samples.to(device)\n",
    "\n",
    "s = bindings['images'].shape\n",
    "\n",
    "assert samples.shape == s, f\"input size {samples.shape} {'>' if dynamic else 'not equal to'} max model size {s}\"\n",
    "binding_addrs['images'] = int(samples.data_ptr())\n",
    "context.execute_v2(list(binding_addrs.values()))\n",
    "\n",
    "pred_logits = bindings['pred_logits'].data\n",
    "pred_points = bindings['pred_points'].data\n",
    "\n",
    "if isinstance(pred_logits, np.ndarray):\n",
    "    pred_logits = torch.tensor(pred_logits, device=device)\n",
    "if isinstance(pred_points, np.ndarray):\n",
    "    pred_points = torch.tensor(pred_points, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
